# -----------------------------------------------
# parameters defining the network architecture

# Can be either "MLP" or "MLP-T"
architecture:  MLP-T

# Input dimension of the network. Should be equal to the number of cosmology parameters you're sampling
input_dim  : 6
# Output dimension of the network. Should be equal to your matrix dimensionality
# Note the actual output dimension will be (N + 1) * N / 2 
output_dim : 20

# These parameters define how many ResNet sub-blocks are in the network, as well as their input / output sizes
num_mlp_blocks: 2
mlp_dims: [50, 100, 200]

# These parameters define various aspects of the transformer block
# If you aren't using the transformer block, you can disregard these arguments
patch_size             : [17, 5]
num_transformer_blocks : 5
num_heads              : 5
embedding              : True        # <- whether to apply possitional embedding
dropout_prob           : 0.25         
freeze_mlp             : True        # <- whether to keeep mlp weights frozen during training
train_mlp_first        : True

# Training parameters
num_epochs: 300
learning_rate: [1.438e-3, 1.e-4, 1.e-5]
batch_size: 600
early_stopping_epochs: -1
weight_initialization: He

train_gaussian_only   : False
start_from_checkpoint : False

# numbers with which to normalize the training set
# Should be updated after generating your specific training set
norm_pos : 1.
norm_neg : 1.

# cosmology parameter bounds. This should line up with what you used to generate your
# training set
parameter_bounds:
 - [50, 100]
 - [0.05, 0.3]
 - [0.75, 4.75]
 - [1, 4]
 - [-4, 4]
 - [-3, 3]

# Where to save the network
save_dir: /Users/JoeyA/Research/CovNet/emulators/ngc_z3/MLP-T/
# Where your training set lives
training_dir: /Users/JoeyA/Research/CovNet/Training-Set-HighZ-NGC/