{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810be3bb-389e-42f7-aea5-eaa972f48868",
   "metadata": {},
   "source": [
    "# Covariance Emulator Demo notebook  \n",
    "\n",
    "The purpose of this notebook is to give you an introduction on how to design, train, and test a neural network emulator that you can use in a cosmological data analysis.  \n",
    "One of the ingredients to modern cosmological inference is the **covariance matrix**  This object is notoriously expensive to calculate, so let's try using machine learning to speed up the process!\n",
    "\n",
    "This notebook is designed to be run on a typical laptop. At the end of this demo, you should be able to:\n",
    "- Gain some familiarity with how neural networks are designed and trained\n",
    "- TODO: fill out this list\n",
    "\n",
    "## Step 1 - Install  \n",
    "\n",
    "This demo uses the `CovNet` package designed by Joe Adamo to emulate covariance matrices. You'll need to download the associated github repository here: https://github.com/jadamo/CovNet. The next few cells will let you install this repo and make sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bdf4b-11b2-4914-919a-735ebcfbbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this line to wherever you downloaded the repository\n",
    "%cd /Users/JoeyA/Research/CovNet\n",
    "\n",
    "# install CovNet so you can use it anywhere on your computer\n",
    "# This should also install all necesary dependencies\n",
    "#!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae7324-9a0f-4fee-99a9-3789ba6c5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run CovNet unit tests (if all of these pass, everything \"should\" work\n",
    "!python -m unittest tests/test_enviornment.py\n",
    "!python -m unittest tests/test_network.py\n",
    "#!python -m unittest tests/test_CovaPT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1b29b-0081-4a2e-8338-b93c05609eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CovNet import Emulator\n",
    "from CovNet import Dataset\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a52bf1-e400-4311-a6c1-eac095059cf0",
   "metadata": {},
   "source": [
    "## Step 2 - Loading in the training set  \n",
    "\n",
    "We need a training set to base our emulator on! Normally, building this set would depend on what you want your emulator to do, and is arguably more important than the network itself. Since we're building a network to generate covariance matrices at different cosmologies, we want to make sure the training set properly spans the range of input parameters we care about. \n",
    "\n",
    "For this demo, we'll use a small mock training set that I pre-computed such that you should be able to do everything on a laptop. There are $~8000$ matrices in total, each of which are 20x20. This data is accessed using the custom `MatrixDataset` class, which takes:\n",
    "* the directory your training data is stored\n",
    "* string specifying if this is the \"training\", \"validation\", or \"testing\" set\n",
    "* whether to only store part of the covariance matrix (the \"Gaussian\" term)\n",
    "* normalization value for positive values of matrices in the training set\n",
    "* normalization value for negative values of matrices in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba00880-9f0d-44bc-87ac-f2af79216895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Update this directory with the location you saved the training set at!\n",
    "training_dir = # DIRECTORY GOES HERE\n",
    "\n",
    "# load and pre-process the training set as a MatrixDataset class\n",
    "# Setting norm_pos and norm_neg to 0 tells CovNet to compute them from the input data\n",
    "train_data = Dataset.MatrixDataset(training_dir, \"training\", 1., False, 0., 0, use_gpu=False)\n",
    "norm_pos, norm_neg = train_data.norm_pos.item(), train_data.norm_neg.item()\n",
    "\n",
    "# load and pre-process the validation and test sets\n",
    "valid_data = Dataset.MatrixDataset(training_dir, \"validation\", 1., False, norm_pos, norm_neg, use_gpu=False)\n",
    "test_data = Dataset.MatrixDataset(training_dir, \"testing\", 1., False, norm_pos, norm_neg, use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4383ee-a917-407b-bdbc-b6779cbde0a8",
   "metadata": {},
   "source": [
    "## Step 3 - Building the network\n",
    "\n",
    "Next, we need to define our network architecture. CovNet uses configuration files to do this such that it is easy to tweak the design either in the file directly, or in code before training. Let's first open an example config file to see what we're dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148f6c9-be23-4c75-b834-986d7fd4ad85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cat config-files/example_file.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d344d7-9b2b-45ea-bbc9-c7fe4753d509",
   "metadata": {},
   "source": [
    "Clearly, there are quite a few knobs we can tweak! For this demo we'll be usng the \"MLP\" architectur, so the main structural things we can change are the number of sub-blocks, and the dimensionality of each sub-block  \n",
    "Let's load in the config file into code such that we can manipulate its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c54c8-9df0-48b1-aa81-62dcdafa9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = Dataset.load_config_file(\"./config-files/example_file.yaml\")\n",
    "print(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ddca4-9329-42d9-bd15-5b093402a95f",
   "metadata": {},
   "source": [
    "Let's play around with this dictionary to design your own network! The following cell will have you define custom network parameters as you see fit. There are, of course, many more network design choices that aren't included in this dictionary (ex: the specific structure of each sub-block). Even so, the parameters you can change should give you an idea of how to design a network for your specific case. If you want to see the specific structure in more detail, check out `Blocks.py` and `Emulator.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8bbd5-71ef-4417-8c5a-c2fa018ee92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# network parameters to be set by YOU!\n",
    "config_dict.save_dir       = # where to save the network\n",
    "config_dict.num_mlp_blocks = \n",
    "config_dict.mlp_dims       = # ex: [40, 80, 150] if num_mlp_blocks = 2\n",
    "\n",
    "config_dict.architecture = \"MLP\"\n",
    "# If you change these you also have to re-define the training / validation / test sets\n",
    "config_dict.norm_pos = norm_pos\n",
    "config_dict.norm_neg = norm_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cac4a-162e-40ca-9536-1e32623b84c5",
   "metadata": {},
   "source": [
    "Now we've designed the actual network, but there are still more choices we need to make on how to train it! These choices are commonly called **hyperparameters**, and in our case include:\n",
    "* The batch size to use during training\n",
    "* the number of epochs to train for (how long to train)\n",
    "* the initial learning rate\n",
    "* How many rounds of training to do\n",
    "* Whether to stop early during training if performance stops improving\n",
    "\n",
    "We also need to define the **loss function**, which is the quantity we will try to minimize during training. We'll use the \"1-norm\" loss function, which is given by:\n",
    "$$L = \\sum_{i,j} \\left| C_{i,j}^\\text{true} - C_{i,j}^\\text{network} \\right|$$\n",
    "You can see from the formula that we go through each element of a matrix we emulate and calculate the absolute difference from the \"true\" value in the training set. We then sum all of these differences to get one loss value for each matrix. As we'll see later, this value will be the main metric for determining how well our network can emulate covariance matrices\n",
    "\n",
    "Use the next cell to define a training scheme yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd5d25-31de-4fdc-85a4-148c29335a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Training parameters to be set by YOU!\n",
    "config_dict.weight_initialization = # [He, normal, xavier]\n",
    "config_dict.num_epochs            = \n",
    "config_dict.learning_rate         = # ex: [1e-2, 1e-5] for 2 rounds\n",
    "config_dict.batch_size            =\n",
    "config_dict.early_stopping_epochs = # -1 for no early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b5cd1-ec1e-40bf-b238-361c7336ba1d",
   "metadata": {},
   "source": [
    "Now that we've defined all our training and network parameters, it's time to actually build the network itself! `CovNet` does this using the `Network_Emulator` class that takes a dictionary of parameters as input\n",
    "\n",
    "**NOTE** at this point PyTorch lets you make the optional decision of defining things on a GPU if one is available on you rmachine. Training on GPU is almost always preferable to CPU in terms of performance, but for this demo you shoulnd't have to worry about that. I've left the code that handles GPU compatability here for completeness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814f411-f4c2-409f-84f1-813ef49f6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Emulator.Network_Emulator(config_dict).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5812219-8e2f-478a-898d-23649906a3e0",
   "metadata": {},
   "source": [
    "## Step 4 - Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12ab8c-4785-4882-af61-3e5771868354",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(config_dict.learning_rate)):\n",
    "    t1 = time.time()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=config_dict.learning_rate[i])\n",
    "    net.Train(optimizer, train_data, valid_data, True, config_dict.save_dir, i)\n",
    "    t2 = time.time()\n",
    "    print(\"Round {:0.0f} done training network!, took {:0.0f} minutes {:0.2f} seconds\\n\".format(i+1, int((t2 - t1)/60), (t2 - t1)%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7201f3-9faf-4798-bf72-e12a8e4fada3",
   "metadata": {},
   "source": [
    "## Step 5 - Test the network  \n",
    "\n",
    "Our main metric for how our network did is the average loss for the test set. To do this we'll use a helper class called `CovNet` that allows us to output covariance matrices from a trained network more easily. This is the class you would call during an MCMC analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c29c9-c7e8-4c3a-a913-75b17d4b0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_emulator = Emulator.CovNet(net.config_dict.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0102ab4-a643-46cc-b8f2-102d0eeb8b03",
   "metadata": {},
   "source": [
    "The following cell computes the average test loss, and compares it to the final average loss for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f993c6-3d5c-4953-8724-43cb254b80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = cov_emulator.get_avg_loss(train_data)\n",
    "valid_loss = cov_emulator.get_avg_loss(valid_data)\n",
    "test_loss =  cov_emulator.get_avg_loss(test_data)\n",
    "\n",
    "print(\"Average training set loss = {:0.4f}\".format(train_loss))\n",
    "print(\"Average validation set loss = {:0.4f}\".format(valid_loss))\n",
    "print(\"Average testing set  loss = {:0.4f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f344dd1-ced6-4506-b362-3b6cb333734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.load(config_dict.save_dir+\"train_data-MLP.dat\", map_location=\"cpu\")\n",
    "epochs = training_data[0,:]    \n",
    "round_start = torch.where(epochs == 0)[0]\n",
    "train_loss = training_data[1,:]\n",
    "valid_loss = training_data[2,:]\n",
    "\n",
    "print(\"final validation loss = {:0.3f}\".format(torch.min(valid_loss)))\n",
    "\n",
    "plt.plot(range(len(epochs)), train_loss, color=\"blue\", label=\"training loss\")\n",
    "plt.plot(range(len(epochs)), valid_loss, color=\"red\", ls=\"--\", label=\"validation loss\")\n",
    "plt.ylim(4, 20)\n",
    "for i in range(1, len(round_start)):\n",
    "    plt.axvline(round_start[i], c=\"black\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"average loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0380f8f-188c-4c15-b26a-4f8848cf2ad7",
   "metadata": {},
   "source": [
    "Let's dig a little deeper and try visualizing how accurately our network can generate individual matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef213350-910b-4501-b8a5-1331ff70b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's look at the raw emulator output, with pre-processing still applied\n",
    "idx = np.random.randint(0, len(test_data))\n",
    "\n",
    "params = test_data[idx][0].detach().numpy()\n",
    "cov_actual = test_data[idx][1].detach()\n",
    "\n",
    "cov_predict = cov_emulator.get_covariance_matrix(params, raw=True).detach().view(20,20)\n",
    "\n",
    "RLoss = F.l1_loss(cov_predict, cov_actual, reduction=\"sum\")\n",
    "\n",
    "print(\"sample \" + str(idx) + \", params:\", params)\n",
    "print(\"Loss value = {:0.3f}\".format(RLoss))\n",
    "\n",
    "cov_predict = cov_predict.numpy()\n",
    "cov_actual = cov_actual.numpy()\n",
    "error = abs((cov_predict - cov_actual) / cov_actual).flatten()\n",
    "error = error[(np.isnan(error) == False)]\n",
    "print(\"error per entry: mean = {:0.3f}%, median = {:0.3f}%\".format(100*np.mean(error), 100*np.median(error)))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].set_title(\"from CovaPT\")\n",
    "axs[1].set_title(\"from network\")\n",
    "img = axs[0].imshow(cov_actual, cmap=\"RdBu\")\n",
    "img = axs[1].imshow(cov_predict, cmap=\"RdBu\", vmin=np.amin(cov_actual), vmax=np.amax(cov_actual))\n",
    "\n",
    "cbar_ax = fig.add_axes([0.94, 0.15, 0.039, 0.7])\n",
    "cbar = fig.colorbar(img, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b219cf-4bfb-4fd3-b81e-0cad31fd7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the actual covariance matrix without pre-processing\n",
    "cov_actual = test_data.get_full_matrix(i)\n",
    "cov_predict = cov_emulator.get_covariance_matrix(params, raw=False)\n",
    "\n",
    "# compile some statistics of each matrix and compare them\n",
    "trace_pred = np.trace(cov_predict)\n",
    "trace_act = np.trace(cov_actual)\n",
    "trace_err = 100*(trace_pred - trace_act) / trace_act\n",
    "\n",
    "det_pred = np.linalg.slogdet(cov_predict)[1]\n",
    "det_act  = np.linalg.slogdet(cov_actual)[1]\n",
    "det_err = 100*(det_pred - det_act) / det_act\n",
    "\n",
    "cond_pred = np.linalg.cond(cov_predict)\n",
    "cond_act = np.linalg.cond(cov_actual)\n",
    "\n",
    "print(\"trace(C) = {:0.3e},\\t actual = {:0.3e},\\t error={:0.3f}%\".format(trace_pred, trace_act, trace_err))\n",
    "print(\"det(C) = {:0.2f},\\t actual = {:0.3f},\\t error={:0.3f}%\".format(det_pred, det_act, det_err))\n",
    "print(\"cond(C) = {:0.2e},\\t actual = {:0.2e}\".format(cond_pred, cond_act))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].set_title(\"from CovaPT\")\n",
    "axs[1].set_title(\"from network\")\n",
    "img = axs[0].imshow(cov_actual, norm=colors.SymLogNorm(linthresh=1., vmin=np.amin(cov_actual), vmax=np.amax(cov_actual)))\n",
    "img = axs[1].imshow(cov_predict, norm=colors.SymLogNorm(linthresh=1., vmin=np.amin(cov_actual), vmax=np.amax(cov_actual)))\n",
    "\n",
    "cbar_ax = fig.add_axes([0.94, 0.15, 0.039, 0.7])\n",
    "cbar = fig.colorbar(img, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181fbc0c-ff57-4c7f-88cf-25203e121b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
